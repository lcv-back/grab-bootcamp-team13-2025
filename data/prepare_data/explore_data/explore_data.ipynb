{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7dd657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2198, 2253, 2260, 2273, 2275, 2290, 2291, 2299, 2339, 2367, 2374, 2375, 2410, 2422, 2424, 2434, 2457, 2463, 2465, 2466, 2472, 2483, 2484, 2486, 2509, 2524, 2527, 2530, 2570, 2613, 2619, 2624, 2634, 2635, 2638, 2643, 2646, 2647, 2725, 2728, 2729, 2733, 2742, 2755, 2780, 2781]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Gi·∫£ s·ª≠ b·∫°n ƒë√£ load DataFrame t·ª´ file ho·∫∑c t·ª´ list of dicts:\n",
    "df = pd.read_json(\"failed_data.json\")\n",
    "\n",
    "# L·ªçc v√† in\n",
    "no_resp_indices = df.loc[\n",
    "    df[\"status\"] == \"parse_failed\",\n",
    "    \"global_index\"\n",
    "].tolist()\n",
    "\n",
    "print(no_resp_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18d160f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_resp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528e3b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ s·ª≠a xong 46 m·ª•c v√† l∆∞u v√†o fixed_selected.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_symptoms_raw(raw: str):\n",
    "    if isinstance(raw, list):\n",
    "        return raw\n",
    "    if raw is None:\n",
    "        return []\n",
    "\n",
    "    raw = raw.strip().strip(\"```json\").strip(\"```\").strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Regex ƒë∆°n c·∫•p, ph√π h·ª£p v·ªõi re module\n",
    "    json_objects = re.findall(r'\\{[^{}]*\\}', raw)\n",
    "    parsed = []\n",
    "    for obj in json_objects:\n",
    "        try:\n",
    "            parsed.append(json.loads(obj))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return parsed\n",
    "\n",
    "def fix_json_entry(entry):\n",
    "    raw = entry.get(\"symptoms_raw\")\n",
    "    parsed = parse_symptoms_raw(raw)\n",
    "\n",
    "    if parsed:\n",
    "        entry[\"symptoms_raw\"] = parsed\n",
    "        entry[\"status\"] = \"ok\"\n",
    "    else:\n",
    "        entry[\"symptoms_raw\"] = []\n",
    "        entry[\"status\"] = \"parse_failed\"\n",
    "    return entry\n",
    "\n",
    "# ==== ‚öôÔ∏è C·∫•u h√¨nh: ch·ªânh c√°c index c·∫ßn s·ª≠a ====\n",
    "target_indexes = no_resp_indices  # üü° Thay b·∫±ng global_index b·∫°n c·∫ßn s·ª≠a\n",
    "input_path = \"final_test.json\"\n",
    "output_path = \"fixed_selected.json\"\n",
    "\n",
    "# ==== üì¶ Load file JSON ====\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ==== üõ† S·ª≠a nh·ªØng entry c√≥ global_index trong danh s√°ch ====\n",
    "fixed_data = []\n",
    "for entry in data:\n",
    "    if entry.get(\"global_index\") in target_indexes:\n",
    "        fixed_data.append(fix_json_entry(entry))\n",
    "    else:\n",
    "        fixed_data.append(entry)\n",
    "\n",
    "# ==== üíæ Ghi ra file m·ªõi ====\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(fixed_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ s·ª≠a xong {len(target_indexes)} m·ª•c v√† l∆∞u v√†o {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1709b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def replace_entries_by_index(file1_path, file2_path, index_list, output_path):\n",
    "    \"\"\"\n",
    "    Thay th·∫ø c√°c entry trong file1 theo global_index n·∫øu n·∫±m trong index_list,\n",
    "    s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ file2.\n",
    "    \"\"\"\n",
    "    with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "        data1 = json.load(f1)\n",
    "    with open(file2_path, 'r', encoding='utf-8') as f2:\n",
    "        data2 = json.load(f2)\n",
    "\n",
    "    # T·∫°o lookup t·ª´ file2 theo global_index\n",
    "    lookup2 = {entry['global_index']: entry for entry in data2}\n",
    "\n",
    "    # Duy·ªát qua file1, thay th·∫ø n·∫øu index n·∫±m trong danh s√°ch\n",
    "    new_data = []\n",
    "    for entry in data1:\n",
    "        idx = entry.get('global_index')\n",
    "        if idx in index_list and idx in lookup2:\n",
    "            new_data.append(lookup2[idx])  # thay b·∫±ng b·∫£n t·ª´ file2\n",
    "        else:\n",
    "            new_data.append(entry)  # gi·ªØ nguy√™n\n",
    "\n",
    "    # Ghi ra file m·ªõi\n",
    "    with open(output_path, 'w', encoding='utf-8') as fout:\n",
    "        json.dump(new_data, fout, ensure_ascii=False, indent=2)\n",
    "\n",
    "# V√≠ d·ª• s·ª≠ d·ª•ng\n",
    "file1 = 'final_test.json'\n",
    "file2 = 'failed_data.json'\n",
    "index_list = no_resp_indices  # danh s√°ch global_index c·∫ßn thay th·∫ø\n",
    "output_file = 'final_test.json'\n",
    "\n",
    "replace_entries_by_index(file1, file2, index_list, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
